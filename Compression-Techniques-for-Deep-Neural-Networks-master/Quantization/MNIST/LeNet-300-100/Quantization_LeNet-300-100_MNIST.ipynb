{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Naveen Lalwani\n\n",
    "#QUANTIZATION<BR>\n",
    "The following python notebook demonstrates quantization of LeNet-300-100 model on MNIST dataset. The full trained and quantized models are saved as tflite models and inferences are checked on the MNIST test images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tensorflow.contrib import lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the <B>MNIST</B> dataset from the Tensorflow examples. The images get saved in the folder named \"MNIST_data\" until otherwise specifed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "testData, testLabels = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of training examples in MNIST dataset is 55,000 has a total of 10 labels. Loading the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples =  55000\n",
      "Training Data shape =  (55000, 784)\n",
      "Training Data labels shape =  (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "numTrain = mnist.train.images.shape[0]\n",
    "trainingData = mnist.train.images[:numTrain,:]\n",
    "trainingLabels = mnist.train.labels[:numTrain,:]\n",
    "print(\"Number of training examples = \", numTrain)\n",
    "print(\"Training Data shape = \", trainingData.shape)\n",
    "print(\"Training Data labels shape = \", trainingLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of training examples in MNIST dataset is 10,000 has a total of 10 labels. Loading the test data. Each example is a 28x28 pixel image flattened in an array with 784 values representing each pixelâ€™s intensity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test examples =  10000\n",
      "Test Data shape =  (10000, 784)\n",
      "Test Data labels shape =  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "numTest = mnist.test.images.shape[0]\n",
    "testData = mnist.test.images[:numTest,:]\n",
    "testLabels = mnist.test.labels[:numTest,:]\n",
    "print(\"Number of test examples = \", numTest)\n",
    "print(\"Test Data shape = \", testData.shape)\n",
    "print(\"Test Data labels shape = \", testLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Displaying the data from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_digit(num):\n",
    "    print(trainingLabels[num])\n",
    "    label = trainingLabels[num].argmax(axis=0)\n",
    "    image = trainingData[num].reshape([28,28])\n",
    "    plt.title('Example: %d  Label: %d' % (num, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()\n",
    "display_digit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Beginning the building of LeNet-300-100 neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Defining the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 4000\n",
    "batch_size = 256\n",
    "display_step = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Network Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Use of Placeholders \n",
    "<list>\n",
    "<li>Placeholder variables used to feed input into the graph.\n",
    "<li>Model variables that are going to be optimized so as to make the model perform better.\n",
    "<li>The model which is essentially just a mathematical function that calculates some output given the input in the placeholder variables and the model variables.\n",
    "<li>A cost measure that can be used to guide the optimization of the variables.\n",
    "<li>An optimization method which updates the variables of the model.\n",
    "</list>\n",
    "Placeholder variables serve as the input to the graph that we may change each time we execute the graph. We call this feeding the placeholder variables.<BR>\n",
    "###Placeholder for input images <BR>\n",
    "This will allow us to change the images that are input to the Tensorflow graph. TThe data type is set to float32 and the shape is set to [None, n_input], where None means that the tensor may hold an arbitrary number of images with each image being a vector of length \"n_input\". <BR>\n",
    "###Placeholder for Labels <BR>\n",
    "This will allow us to change the labesl that are true labels with the images in the placeholder X.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "X = tf.placeholder(tf.float32, shape = [None, n_input], name = \"X\") # Placeholder for Images\n",
    "Y = tf.placeholder(tf.float32, shape = [None, n_classes], name = \"Y\") # Placeholder for Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Defining variables to be optimized "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables that are first optimized are weights and is defined as TensorFlow variable that is initialized randomly and whose shape is [n_input, n_classes], so it is a 2 dimensional tensor(matrix) with 784 rows and 10 columns.<BR>\n",
    "##Defining weights & biases for the three layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # Fully Connected Layer 1: 784 input channels, 300 output channels\n",
    "    'w1' : tf.Variable(tf.random_normal([784, 300]), name = 'w1'),\n",
    "    # Fully Connected Layer 2: 300 input channels, 100 output channels\n",
    "    'w2' : tf.Variable(tf.random_normal([300, 100]), name = 'w2'),\n",
    "    # Fully Connected Layer 3: 100 input channels, 10 (number of classes) output channels\n",
    "    'w3' : tf.Variable(tf.random_normal([100, 10]), name = 'w3')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random_normal([300]), name = 'b1'),\n",
    "    'b2' : tf.Variable(tf.random_normal([100]), name = 'b2'),\n",
    "    'b3' : tf.Variable(tf.random_normal([10]), name = 'b3')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING THE LENET-300-100 MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet_300_100(x, weight, bias):\n",
    "    b_min1 = tf.reduce_min(bias['b1'])\n",
    "    b_max1 = tf.reduce_max(bias['b1'])\n",
    "    b_fake_quant1 = tf.fake_quant_with_min_max_vars(bias['b1'], \n",
    "                    min=b_min1, \n",
    "                    max=b_max1, \n",
    "                    narrow_range=True, \n",
    "                    name=\"b_weights1\")\n",
    "    \n",
    "    \n",
    "    b_min2 = tf.reduce_min(bias['b2'])\n",
    "    b_max2 = tf.reduce_max(bias['b2'])\n",
    "    b_fake_quant2 = tf.fake_quant_with_min_max_vars(bias['b2'], \n",
    "                    min=b_min2, \n",
    "                    max=b_max2, \n",
    "                    narrow_range=True,\n",
    "                    name=\"b_weights2\")\n",
    "    \n",
    "    \n",
    "    b_min3 = tf.reduce_min(bias['b3'])\n",
    "    b_max3 = tf.reduce_max(bias['b3'])\n",
    "    b_fake_quant3 = tf.fake_quant_with_min_max_vars(bias['b3'], \n",
    "                    min=b_min3, \n",
    "                    max=b_max3, \n",
    "                    narrow_range=True,\n",
    "                    name=\"b_weights3\")\n",
    "    \n",
    "    # Fully Connected Layer 1\n",
    "    # First multiply the weights with inputs, then add the bias, then apply RELU activation\n",
    "    w_min1 = tf.reduce_min(weight['w1'])\n",
    "    w_max1 = tf.reduce_max(weight['w1'])\n",
    "    w_fake_quant1 = tf.fake_quant_with_min_max_vars(weight['w1'], \n",
    "                    min=w_min1, \n",
    "                    max=w_max1, \n",
    "                    narrow_range=True, \n",
    "                    name=\"quant_weights1\")\n",
    "    fc1 = tf.add(tf.matmul(x, w_fake_quant1), b_fake_quant1) # Linear Function\n",
    "    fc1 = tf.nn.relu(fc1) # Activation Function\n",
    "    fc1_fake_quant1 = tf.fake_quant_with_min_max_vars(fc1, \n",
    "                    min=-500.0, \n",
    "                    max=500.0, \n",
    "                    narrow_range=False,\n",
    "                    name=\"act_weights1\")\n",
    "    \n",
    "    w_min2 = tf.reduce_min(weight['w2'])\n",
    "    w_max2 = tf.reduce_max(weight['w2'])\n",
    "    w_fake_quant2 = tf.fake_quant_with_min_max_vars(weight['w2'], \n",
    "                    min=w_min2, \n",
    "                    max=w_max2, \n",
    "                    narrow_range=True, # will be explained below\n",
    "                    name=\"quant_weights2\")\n",
    "    \n",
    "    # Fully Connected Layer 2\n",
    "    fc2 = tf.add(tf.matmul(fc1_fake_quant1, w_fake_quant2), b_fake_quant2) # Linear Function\n",
    "    fc2 = tf.nn.relu(fc2) # Activation Function\n",
    "    fc2_fake_quant = tf.fake_quant_with_min_max_vars(fc2, \n",
    "                    min=-500.0, \n",
    "                    max=500.0, \n",
    "                    narrow_range=False,\n",
    "                    name=\"act_weights2\")\n",
    "    \n",
    "    w_min3 = tf.reduce_min(weight['w3'])\n",
    "    w_max3 = tf.reduce_max(weight['w3'])\n",
    "    w_fake_quant3 = tf.fake_quant_with_min_max_vars(weight['w3'], \n",
    "                    min=w_min3, \n",
    "                    max=w_max3, \n",
    "                    narrow_range=True,\n",
    "                    name=\"quant_weights3\")\n",
    "    # Ouput Layer\n",
    "    out = tf.add(tf.matmul(fc2_fake_quant, w_fake_quant3), b_fake_quant3) # Output Layer\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Training the model <BR>\n",
    "<B>Logits</B> is interpreted to be the unnormalised (or not-yet normalised) predictions (or outputs) of a model. These can give results, but we don't normally stop with logits, because interpreting their raw values is not easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for the input for all the classes\n",
    "logits = lenet_300_100(X, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Cross Entropy Loss \n",
    "Compute the cross entropy loss for the model for all classes. Cross Entropy is a continuous function that is always positive and if the predicted output of the model exactly \n",
    " matches the desired output then the cross entropy loss equals zero. The goal of the optimization is therefore to minimize the cross-entropy loss so it gets as close to zero \n",
    " as possible by changing the weights and biases of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have calculated the cross-entropy for each of the image classifications so we have a measure of how well the model performs on each image individually but in order to use \n",
    "the cross-entropy to guide the optimization of the model;s variables we need a single scalar value, so we simply take the mean of the cross-entropy for all the image \n",
    "classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_op = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have the cost in 'loss_op', variable, we need an optimizer to reduce the cost.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "\n",
    "# Minimize the optimization function i.e. minimize the loss.\n",
    "train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##How to measure performace? <BR>\n",
    "We measure the accuracy by measuring the actual prediction and by calculated prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correct prediction by getting class with maximum probability and get accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "\n",
    "# This calculates the classification accuracy by first type-casting the vector of booleans to floats, so that False becomes 0 and True \n",
    "# becomes 1, and then calculating the average of these numbers.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SAVING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saver = tf.train.Saver([weights['w1'], weights['w2'], weights['w3'], biases['b1'], biases['b2'], biases['b3'] ])\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Initializing all the variables & Running tensorflow session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Cost: None, Accuracy on batch: 96.09375 %\n",
      "Train Accuracy after 500 on training data:  94.07272934913635 %\n",
      "Epoch 1000, Cost: None, Accuracy on batch: 96.484375 %\n",
      "Train Accuracy after 1000 on training data:  97.14727401733398 %\n",
      "Epoch 1500, Cost: None, Accuracy on batch: 99.21875 %\n",
      "Train Accuracy after 1500 on training data:  98.07454347610474 %\n",
      "Epoch 2000, Cost: None, Accuracy on batch: 98.046875 %\n",
      "Train Accuracy after 2000 on training data:  97.83999919891357 %\n",
      "Epoch 2500, Cost: None, Accuracy on batch: 99.609375 %\n",
      "Train Accuracy after 2500 on training data:  98.48363399505615 %\n",
      "Epoch 3000, Cost: None, Accuracy on batch: 98.4375 %\n",
      "Train Accuracy after 3000 on training data:  98.69636297225952 %\n",
      "Epoch 3500, Cost: None, Accuracy on batch: 98.4375 %\n",
      "Train Accuracy after 3500 on training data:  98.23636412620544 %\n",
      "Epoch 4000, Cost: None, Accuracy on batch: 99.21875 %\n",
      "Train Accuracy after 4000 on training data:  99.0781843662262 %\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Optimization Finished\n",
      "\n",
      "Now testing accuracy on the complete data, we have:\n",
      "\n",
      "Training Accuracy: 0.99078184\n",
      "Test Accuracy: 0.9649\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "def next_batch(batch_size, data, labels):\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[: batch_size]\n",
    "    data_shuffle = [data[i] for i in idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Running Initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    # For saving cost history and accuracy history on batches\n",
    "    cost_hist, acc_hist = [], []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        batch_x, batch_y = next_batch(batch_size, trainingData, trainingLabels)\n",
    "        sess.run(train_op, feed_dict = { X : batch_x, Y : batch_y })\n",
    "        if epoch % display_step == 0:\n",
    "            # Calculating Loss and Accuracy on the current Epoch\n",
    "            loss, acc = sess.run([train_op, accuracy], feed_dict = { X : batch_x, Y : batch_y })\n",
    "            cost_hist.append(loss)\n",
    "            acc_hist.append(acc)\n",
    "            print('Epoch ' + str(epoch) + ', Cost: ' + str(loss) + ', Accuracy on batch: ' + str(acc * 100) + ' %')\n",
    "            print(\"Train Accuracy after \" + str(epoch) + \" on training data: \", str(accuracy.eval({X:trainingData, Y:trainingLabels}) * 100) + ' %')\n",
    "    #W = sess.run(weights)\n",
    "    #B = sess.run(biases)\n",
    "    print('-' * 70)\n",
    "    print('\\nOptimization Finished\\n')\n",
    "    print('Now testing accuracy on the complete data, we have:\\n')\n",
    "    print(\"Training Accuracy:\", accuracy.eval({X:trainingData, Y:trainingLabels}))\n",
    "    print(\"Test Accuracy:\", accuracy.eval({X:testData, Y:testLabels}))\n",
    "    \n",
    "    # Saving the full precision model\n",
    "    converter = lite.TFLiteConverter.from_session(sess, [X], [logits])\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"FullPrecision_float32_model.tflite\", \"wb\").write(tflite_model)\n",
    "    \n",
    "    # Saving the quantized model\n",
    "    converter = lite.TFLiteConverter.from_session(sess, [X], [logits])\n",
    "    converter.inference_input_type = tf.float32\n",
    "    converter.default_ranges_stats = (0., 6.)\n",
    "    input_mean = 128\n",
    "    input_stddev = 255\n",
    "    input_arrays = converter.get_input_arrays()\n",
    "    converter.quantized_input_stats = {input_arrays[0] : (input_mean, input_stddev)}\n",
    "    converter.post_training_quantize = True\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"Quantized_int8_model.tflite\", \"wb\").write(tflite_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
