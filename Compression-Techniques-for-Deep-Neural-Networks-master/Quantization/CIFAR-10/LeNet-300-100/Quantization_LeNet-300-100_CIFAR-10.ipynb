{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Naveen Lalwani\n",
    "# Script to train and Quantize baseline model LeNet-300-100 on CIFAR-10 dataset\n\n", 
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from collections import Counter\n",
    "from tensorflow.contrib import lite\n",
    "from keras.utils import np_utils\n",
    "from keras import layers\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Network Parameters </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 500\n",
    "learning_rate = 0.001\n",
    "display_step = 50\n",
    "n_input = 3072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Loading CIFAR 10 Dataset and Preprocessing it </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) =  tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Enabling One Hot Encoding\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Changing input image datatype to float\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizaig data\n",
    "x_train  /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_train = x_train.reshape([50000, 3072])\n",
    "x_test = x_test.reshape([10000, 3072])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3072], name = \"X\") # Placeholder for Images 32 X 32 size with 3 RGB channels\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 10], name = \"Y\") # Placeholder for Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # Fully Connected Layer 1: 3072 input channels, 300 output channels\n",
    "    'w1' : tf.Variable(tf.random_normal([3072, 300]), name = 'w1'),\n",
    "    # Fully Connected Layer 2: 300 input channels, 100 output channels\n",
    "    'w2' : tf.Variable(tf.random_normal([300, 100]), name = 'w2'),\n",
    "    # Fully Connected Layer 3: 100 input channels, 10 (number of classes) output channels\n",
    "    'w3' : tf.Variable(tf.random_normal([100, 10]), name = 'w3')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random_normal([300]), name = 'b1'),\n",
    "    'b2' : tf.Variable(tf.random_normal([100]), name = 'b2'),\n",
    "    'b3' : tf.Variable(tf.random_normal([10]), name = 'b3')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet_300_100(x, weight, bias):\n",
    "    b_min1 = tf.reduce_min(bias['b1'])\n",
    "    b_max1 = tf.reduce_max(bias['b1'])\n",
    "    b_fake_quant1 = tf.fake_quant_with_min_max_vars(bias['b1'], \n",
    "                    min=b_min1, \n",
    "                    max=b_max1, \n",
    "                    narrow_range=True, \n",
    "                    name=\"b_weights1\")\n",
    "    \n",
    "    \n",
    "    b_min2 = tf.reduce_min(bias['b2'])\n",
    "    b_max2 = tf.reduce_max(bias['b2'])\n",
    "    b_fake_quant2 = tf.fake_quant_with_min_max_vars(bias['b2'], \n",
    "                    min=b_min2, \n",
    "                    max=b_max2, \n",
    "                    narrow_range=True,\n",
    "                    name=\"b_weights2\")\n",
    "    \n",
    "    \n",
    "    b_min3 = tf.reduce_min(bias['b3'])\n",
    "    b_max3 = tf.reduce_max(bias['b3'])\n",
    "    b_fake_quant3 = tf.fake_quant_with_min_max_vars(bias['b3'], \n",
    "                    min=b_min3, \n",
    "                    max=b_max3, \n",
    "                    narrow_range=True,\n",
    "                    name=\"b_weights3\")\n",
    "    \n",
    "    # Fully Connected Layer 1\n",
    "    # First multiply the weights with inputs, then add the bias, then apply RELU activation\n",
    "    w_min1 = tf.reduce_min(weight['w1'])\n",
    "    w_max1 = tf.reduce_max(weight['w1'])\n",
    "    w_fake_quant1 = tf.fake_quant_with_min_max_vars(weight['w1'], \n",
    "                    min=w_min1, \n",
    "                    max=w_max1, \n",
    "                    narrow_range=True, \n",
    "                    name=\"quant_weights1\")\n",
    "    \n",
    "    # Fully Connected Layer 1\n",
    "    # First multiply the weights with inputs, then add the bias, then apply RELU activation\n",
    "    fc1 = tf.add(tf.matmul(x, weight['w1']), bias['b1']) # Linear Function\n",
    "    fc1 = tf.nn.relu(fc1) # Activation Function\n",
    "    \n",
    "    # Fully Connected Layer 2\n",
    "    fc2 = tf.add(tf.matmul(fc1, weight['w2']), bias['b2']) # Linear Function\n",
    "    fc2 = tf.nn.relu(fc2) # Activation Function\n",
    "    \n",
    "    # Ouput Layer\n",
    "    out = tf.add(tf.matmul(fc2, weight['w3']), bias['b3']) # Output Layer\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Evaluating Model Performance </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for the input for all the classes\n",
    "logits = lenet_300_100(X, weights, biases)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = Y)\n",
    "loss_op = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Using ADAM optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Get correct prediction by getting class with maximum probability and get accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "\n",
    "# This calculates the classification accuracy by first type-casting the vector of booleans to floats, so that False becomes 0 and True \n",
    "# becomes 1, and then calculating the average of these numbers.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training------------------\n",
      "Epoch 50, Cost: None, Accuracy on batch: 43.75 %\n",
      "Test Accuracy:  34.72000062465668 %\n",
      "Epoch 100, Cost: None, Accuracy on batch: 81.25 %\n",
      "Test Accuracy:  38.71999979019165 %\n",
      "Epoch 150, Cost: None, Accuracy on batch: 56.25 %\n",
      "Test Accuracy:  40.16999900341034 %\n",
      "Epoch 200, Cost: None, Accuracy on batch: 93.75 %\n",
      "Test Accuracy:  44.67000067234039 %\n",
      "Epoch 250, Cost: None, Accuracy on batch: 62.5 %\n",
      "Test Accuracy:  45.089998841285706 %\n",
      "Epoch 300, Cost: None, Accuracy on batch: 68.75 %\n",
      "Test Accuracy:  44.5499986410141 %\n",
      "Epoch 350, Cost: None, Accuracy on batch: 81.25 %\n",
      "Test Accuracy:  44.200000166893005 %\n",
      "Epoch 400, Cost: None, Accuracy on batch: 93.75 %\n",
      "Test Accuracy:  43.57999861240387 %\n",
      "Epoch 450, Cost: None, Accuracy on batch: 87.5 %\n",
      "Test Accuracy:  43.43000054359436 %\n",
      "Epoch 500, Cost: None, Accuracy on batch: 93.75 %\n",
      "Test Accuracy:  43.5699999332428 %\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Optimization Finished\n",
      "\n",
      "Now testing accuracy on the complete data, we have:\n",
      "\n",
      "Train Accuracy:  79.62800025939941 %\n",
      "Test Accuracy:  43.5699999332428 %\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Set to use GPU for training Convolution layers and allow the memory to grow so that tensors can be loaded.\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    num_examples = 50000\n",
    "    acc_hist = []\n",
    "    cost_hist = []\n",
    "    batch_x = x_train\n",
    "    batch_y = y_train\n",
    "    print(\"Training------------------\")\n",
    "    for i in range(1, epochs + 1):\n",
    "        x_train, y_train = shuffle(x_train, y_train)\n",
    "        for offset in range(0, num_examples, batch_size):\n",
    "            end = offset + batch_size\n",
    "            batch_x, batch_y = x_train[offset:end], y_train[offset:end]\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y}) \n",
    "        if (i % display_step == 0):\n",
    "            loss, acc = sess.run([train_op, accuracy], feed_dict = {X: batch_x, Y: batch_y})\n",
    "            loss = loss\n",
    "            cost_hist.append(loss)\n",
    "            acc_hist.append(acc)\n",
    "            print('Epoch ' + str(i) + ', Cost: ' + str(loss) + ', Accuracy on batch: ' + str(acc * 100) + ' %')\n",
    "            print(\"Test Accuracy: \", str(accuracy.eval({ X : x_test, Y : y_test}) * 100) + ' %')\n",
    "    print('-' * 70)\n",
    "    print('\\nOptimization Finished\\n')\n",
    "    print('Now testing accuracy on the complete data, we have:\\n')\n",
    "    acc1 = 0\n",
    "    for i in range(0, num_examples, 5000):\n",
    "        end = i + 5000\n",
    "        acc1 = acc1 + accuracy.eval({ X : x_train[i:end], Y : y_train[i:end]})\n",
    "    print(\"Train Accuracy: \", str((acc1 / 10) * 100) + ' %')\n",
    "    print(\"Test Accuracy: \", str(accuracy.eval({ X : x_test, Y : y_test}) * 100) + ' %')\n",
    "    \n",
    "    # Saving the full precision model\n",
    "    converter = lite.TFLiteConverter.from_session(sess, [X], [logits])\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"LeNet_float32_model_CIFAR-10.tflite\", \"wb\").write(tflite_model)\n",
    "    \n",
    "    # Saving the quantized model\n",
    "    converter = lite.TFLiteConverter.from_session(sess, [X], [logits])\n",
    "    converter.inference_input_type = tf.float32\n",
    "    converter.default_ranges_stats = (0., 6.)\n",
    "    input_mean = 128\n",
    "    input_stddev = 128\n",
    "    input_arrays = converter.get_input_arrays()\n",
    "    converter.quantized_input_stats = {input_arrays[0] : (input_mean, input_stddev)}\n",
    "    converter.post_training_quantize = True\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"LeNet_int8_model_CIFAR-10.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
