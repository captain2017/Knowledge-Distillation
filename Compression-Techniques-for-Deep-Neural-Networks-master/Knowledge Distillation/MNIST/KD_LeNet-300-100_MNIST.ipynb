{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bq0CKpLHM28d"
   },
   "outputs": [],
   "source": [
    "# Author: Naveen Lalwani\n",
    "# Script to distill knowledge of LeNet-300-100 model trained on MNIST to student model\n\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrkRYyvLNFd4"
   },
   "outputs": [],
   "source": [
    "# Preprocessing for smaller model\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# Normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# One Hot Encoding\n",
    "y_train = to_categorical(y_train.astype('float32'))\n",
    "y_test = to_categorical(y_test.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vpjoNKIXNHQn"
   },
   "outputs": [],
   "source": [
    "# Teacher Model: LeNet-300-100\n",
    "def lenet_300_100_model():\n",
    "    inputs = layers.Input(shape = (784,))\n",
    "    \n",
    "    x = layers.Dense(300, activation='relu', name='FC1')(inputs)\n",
    "    \n",
    "    x = layers.Dense(100, activation='relu', name='FC2')(x)\n",
    "\n",
    "    x = layers.Dense(10, name='logits')(x)\n",
    "    preds = layers.Activation('softmax', name='Softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=preds)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U4C9OddFApsk"
   },
   "source": [
    "#**Build Model LeNet-300-100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "DF54m5H3NIEp",
    "outputId": "a07e5509-d531-4d1a-ea72-d4c3883d6b1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "Softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lenet_300_100_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "5Ux0E3V7NKhr",
    "outputId": "97794973-0a0e-4b67-d25a-abbe2b741d5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.4256 - categorical_accuracy: 0.8852\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1568 - categorical_accuracy: 0.9542\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1070 - categorical_accuracy: 0.9691\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0783 - categorical_accuracy: 0.9774\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0607 - categorical_accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1f42cd3c18>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size = 512) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "HqJk8ectNMkJ",
    "outputId": "c7016c7d-45b2-45f1-c22d-f35c7f42bd43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0811 - categorical_accuracy: 0.9759\n",
      "Test Loss: 0.08111305869612843\n",
      "Test Accuracy: 0.9759\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vINHLjraNlXm"
   },
   "outputs": [],
   "source": [
    "getSoftmaxKnowledge = Model(inputs=model.input, outputs=model.get_layer(\"logits\").output)\n",
    "model_logits = getSoftmaxKnowledge.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GH2ZG8cFNyh2"
   },
   "outputs": [],
   "source": [
    "# Defining function described by Geoffrey Hinton in his paper of Knowledge Distillation\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    logits = logits / temperature\n",
    "    return (np.exp(logits) / np.sum(np.exp(logits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1KDZU8oAOLzo"
   },
   "outputs": [],
   "source": [
    "# Temperature is a hyperparameter\n",
    "temperature = 3\n",
    "softened_train_prob = softmax_with_temperature(model_logits, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVJnoR5oObMV"
   },
   "outputs": [],
   "source": [
    "# Model Definition for the Student Model\n",
    "def build_small_model():\n",
    "    inputs = layers.Input(shape = (784,))\n",
    "    \n",
    "    x = layers.Dense(50, activation='relu', name='FC1')(inputs)\n",
    "    \n",
    "    x = layers.Dense(10, name='logits')(x)\n",
    "    \n",
    "    preds = layers.Activation('softmax', name='Softmax')(x)\n",
    "  \n",
    "    model = Model(inputs=inputs, outputs=preds)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "BiZ8cWtYOy3B",
    "outputId": "821ef19f-51d4-44e4-af1c-93706ba4cec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "Softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "small_model = build_small_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KNtyE55UA-Fi"
   },
   "source": [
    "# **Distilling Knowledge in the student model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1830
    },
    "colab_type": "code",
    "id": "__MrMb0mO9Gm",
    "outputId": "c0eb21b3-44ff-45d6-da6e-2790a2832433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 8.9660e-06 - categorical_accuracy: 0.9817\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 8.9663e-06 - categorical_accuracy: 0.9816\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9658e-06 - categorical_accuracy: 0.9818\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9649e-06 - categorical_accuracy: 0.9818\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 8.9644e-06 - categorical_accuracy: 0.9818\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9636e-06 - categorical_accuracy: 0.9819\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 8.9626e-06 - categorical_accuracy: 0.9820\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9619e-06 - categorical_accuracy: 0.9824\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 8.9613e-06 - categorical_accuracy: 0.9826\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 8.9604e-06 - categorical_accuracy: 0.9824\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 8.9596e-06 - categorical_accuracy: 0.9826\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9589e-06 - categorical_accuracy: 0.9826\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9581e-06 - categorical_accuracy: 0.9825\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9576e-06 - categorical_accuracy: 0.9830\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9567e-06 - categorical_accuracy: 0.9832\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9561e-06 - categorical_accuracy: 0.9830\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 8.9553e-06 - categorical_accuracy: 0.9831\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9547e-06 - categorical_accuracy: 0.9833\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9540e-06 - categorical_accuracy: 0.9831\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9536e-06 - categorical_accuracy: 0.9835\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9529e-06 - categorical_accuracy: 0.9837\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9523e-06 - categorical_accuracy: 0.9834\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9515e-06 - categorical_accuracy: 0.9838\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 8.9512e-06 - categorical_accuracy: 0.9836\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9505e-06 - categorical_accuracy: 0.9838\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 8.9500e-06 - categorical_accuracy: 0.9841\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9497e-06 - categorical_accuracy: 0.9840\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 8.9491e-06 - categorical_accuracy: 0.9841\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 8.9484e-06 - categorical_accuracy: 0.9840\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9480e-06 - categorical_accuracy: 0.9840\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9476e-06 - categorical_accuracy: 0.9839\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9471e-06 - categorical_accuracy: 0.9842\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 8.9466e-06 - categorical_accuracy: 0.9840\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9461e-06 - categorical_accuracy: 0.9843\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9457e-06 - categorical_accuracy: 0.9844\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9452e-06 - categorical_accuracy: 0.9842\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 8.9449e-06 - categorical_accuracy: 0.9843\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 8.9443e-06 - categorical_accuracy: 0.9844\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 8.9439e-06 - categorical_accuracy: 0.9844\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 8.9437e-06 - categorical_accuracy: 0.9846\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 8.9432e-06 - categorical_accuracy: 0.9845\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 8.9426e-06 - categorical_accuracy: 0.9845\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 8.9423e-06 - categorical_accuracy: 0.9846\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 8.9420e-06 - categorical_accuracy: 0.9847\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 8.9415e-06 - categorical_accuracy: 0.9848\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 8.9410e-06 - categorical_accuracy: 0.9847\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 8.9407e-06 - categorical_accuracy: 0.9847\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 8.9403e-06 - categorical_accuracy: 0.9847\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 8.9399e-06 - categorical_accuracy: 0.9847\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 8.9397e-06 - categorical_accuracy: 0.9849\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.3282 - categorical_accuracy: 0.9676\n",
      "Test Loss: 0.32816381804943084\n",
      "Test Accuracy: 0.9676\n"
     ]
    }
   ],
   "source": [
    "# Optimization = Adam\n",
    "# Loss = Cross Entropy loss\n",
    "# Epochs = 50\n",
    "# Trained with dark knowledge\n",
    "\n",
    "small_model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "small_model.fit(x_train, softened_train_prob, epochs=50, batch_size=128)\n",
    "\n",
    "test_loss, test_acc = small_model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjO-qlQaQOhx"
   },
   "outputs": [],
   "source": [
    "small_model.save('model_50_LeNet-300-100_Distilled.h5')\n",
    "model.save('model_LeNet-300-100.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "KD_LeNet-3-1_MNIST",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
