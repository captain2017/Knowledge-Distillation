{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QT-WQCRF0Amn"
   },
   "outputs": [],
   "source": [
    "# Author: Naveen Lalwani\n",
    "# Script to train student model on CIFAR-10 dataset without knowledge distillation\n\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# To grow the memory usage as is needed by the process\n",
    "# Get rid of the error: cuDNN failed to initialize\n\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tensorflow.contrib import lite\n",
    "from keras.utils import np_utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwMPjvMxmYy7"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 4000\n",
    "learning_rate = 0.001\n",
    "display_step = 50\n",
    "n_input = 3072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tLFordX_0Amt"
   },
   "source": [
    "Importing the <B>CIFAR 10</B> dataset from the Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcxMqGMU0Amu"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) =  tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Enabling One Hot Encoding\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Changing input image datatype to float\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizaig data\n",
    "x_train  /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_train = x_train.reshape([50000, 3072])\n",
    "x_test = x_test.reshape([10000, 3072])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgYGe0j80Am0"
   },
   "source": [
    "<B>Building of Single hidden layer with 50 units neural network. </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "trxYR_490Am9"
   },
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "X = tf.placeholder(tf.float32, shape = [None, n_input], name = \"X\") # Placeholder for Images\n",
    "Y = tf.placeholder(tf.float32, shape = [None, num_classes], name = \"Y\") # Placeholder for Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49gkPQgA0Am_"
   },
   "source": [
    "#Defining variables to be optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VIVHzDaH0AnA"
   },
   "source": [
    "##Defining weights & biases for the three layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylSiK0iZ0AnB"
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # Fully Connected Layer 1: 3072 input channels, 100 output channels\n",
    "    'w1' : tf.Variable(tf.random_normal([3072, 50]), name = 'w1'),\n",
    "    # Fully Connected Layer 2: 100 input channels, 10 (number of classes) output channels\n",
    "    'w2' : tf.Variable(tf.random_normal([50, 10]), name = 'w2')\n",
    "}\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random_normal([50]), name = 'b1'),\n",
    "    'b2' : tf.Variable(tf.random_normal([10]), name = 'b2')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vsP9955a0AnD"
   },
   "outputs": [],
   "source": [
    "def model_50(x, weight, bias):\n",
    "    # Fully Connected Layer 1\n",
    "    fc1 = tf.add(tf.matmul(x, weight['w1']), bias['b1']) # Linear Function\n",
    "    fc1 = tf.nn.relu(fc1) # Activation Function\n",
    "    \n",
    "    # Ouput Layer\n",
    "    out = tf.add(tf.matmul(fc1, weight['w2']), bias['b2']) # Output Layer\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JzEDvuvf0AnF"
   },
   "source": [
    "<B> Training the model </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwgh19ZI0AnG"
   },
   "outputs": [],
   "source": [
    "# Get probabilities for the input for all the classes\n",
    "logits = model_50(X, weights, biases)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = Y)\n",
    "loss_op = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Since we have the cost in 'loss_op', variable, we need an optimizer to reduce the cost.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "\n",
    "# Minimize the optimization function i.e. minimize the loss.\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Get correct prediction by getting class with maximum probability and get accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "\n",
    "# This calculates the classification accuracy by first type-casting the vector of booleans to floats, so that False becomes 0 and True \n",
    "# becomes 1, and then calculating the average of these numbers.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCGrYfrh0AnI"
   },
   "source": [
    "#Initializing all the variables & Running tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDyBVrLN0AnJ"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3009
    },
    "colab_type": "code",
    "id": "0ptD5vxg0AnM",
    "outputId": "d2c7b7cb-afc2-4777-c814-1570c26cdb0d"
   },
   "source": [
    "def next_batch(batch_size, data, labels):\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[: batch_size]\n",
    "    data_shuffle = [data[i] for i in idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Running Initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    # For saving cost history and accuracy history on batches\n",
    "    cost_hist, acc_hist = [], []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        batch_x, batch_y = next_batch(batch_size, x_train, y_train)\n",
    "        sess.run(train_op, feed_dict = { X : batch_x, Y : batch_y })\n",
    "        if epoch % display_step == 0:\n",
    "            # Calculating Loss and Accuracy on the current Epoch\n",
    "            loss, acc = sess.run([train_op, accuracy], feed_dict = { X : batch_x, Y : batch_y })\n",
    "            cost_hist.append(loss)\n",
    "            acc_hist.append(acc)\n",
    "            print('Epoch ' + str(epoch) + ', Cost: ' + str(loss) + ', Accuracy on batch: ' + str(acc * 100) + ' %')\n",
    "            print(\"Train Accuracy after \" + str(epoch) + \" on training data: \", str(accuracy.eval({X: x_train, Y: y_train}) * 100) + ' %')\n",
    "    \n",
    "    print('-' * 70)\n",
    "    print('\\nOptimization Finished\\n')\n",
    "    print('Now testing accuracy on the complete data, we have:\\n')\n",
    "    print(\"Training Accuracy:\", accuracy.eval({X:x_train, Y: y_train}))\n",
    "    print(\"Test Accuracy:\", accuracy.eval({X:x_test, Y: y_test}))\n",
    "    \n",
    "    # Saving the full precision model\n",
    "    converter = lite.TFLiteConverter.from_session(sess, [X], [logits])\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"Student_model_CIFAR10.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Q5egYyH0AnP"
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "StudentModel_CIFAR.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
